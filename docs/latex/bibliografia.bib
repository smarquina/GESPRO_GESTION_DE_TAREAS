@article{ art:bees_decline,
    author = {{Greenpeace Laboratories Research}},
    title = {{Bees in Decline put pollinators and agriculture}},
    year = {2013},
    url = {http://www.greenpeace.org/switzerland/Global/international/publications/agriculture/2013/BeesInDecline.pdf},
    abstract = {A review of factors that put pollinators and agriculture in Europe at risk},
    pages = {48}
}

@article{ art:ccd,
    abstract = {Colony collapse disorder (CCD) is a phenomenon in which worker bees from a beehive or European honey bee colony abruptly disappear. While such disappearances have occurred throughout the history of apiculture, and were known by various names (disappearing disease, spring dwindle, May disease, autumn collapse, and fall dwindle disease),[1] the syndrome was renamed colony collapse disorder in late 2006[2] in conjunction with a drastic rise in the number of disappearances of Western honeybee colonies in North America at that time. /// growth of neonicotinoids such as clothianidin and imidacloprid, some of the most widely-used pesticides in the world, has roughly tracked rising bee deaths since 2005 /// Colony collapse is significant economically because many agricultural crops worldwide are pollinated by European honey bees. Shortages in the US have increased the cost to farmers, renting bees for pollination services, up to 20{\%} at times. /// Losses had remained stable since the 1990s at 17{\%}-20{\%} per year attributable to a variety of factors, such as mites, diseases, and management stress. /// They are responsible for pollination of approximately one third of the United States' crop species, including such species as almonds, peaches, soybeans, apples, pears, cherries, raspberries, blackberries, cranberries, watermelons, cantaloupes, cucumbers and strawberries.},
    author = {Kaplan, J. K.},
    isbn = {0002-7626},
    issn = {00027626},
    journal = {Agricultural Research},
    number = {June},
    pages = {8--11},
    title = {{Colony Collapse Disorder - A Complex Buzz}},
    url = {https://agresearchmag.ars.usda.gov/AR/archive/2008/May/colony0508.pdf},
    year = {2008}
}

@article{ art:campbell2008,
    abstract = {The flight activity of a honey bee colony is an impor- tant indicator of its strength and condition. We propose the use of video sensing to monitor arrivals and depar- tures at the hive entrance. We describe the challenges of tracking and counting bees visually in the uncontrolled outdoor environment of an apiary, and detail a hard- ware platform and software algorithms we have devel- oped to meet many of those challenges. Finally, we dis- cuss our preparations for rigorously evaluating the pro- posed monitoring system and describe early results.},
    author = {Campbell, Jason and Mummert, Lily and Sukthankar, Rahul},
    journal = {Visual observation analysis of animal insect behavior ICPR},
    pages = {1--4},
    title = {{Video Monitoring of Honey Bee Colonies at the Hive Entrance}},
    url = {http://homepages.inf.ed.ac.uk/rbf/VAIB08PAPERS/vaib9\_mummert.pdf},
    volume = {8},
    year = {2008}
}

@article{ art:lundie1925,
    abstract = {The objective of this case study was to obtain some first-hand information about the functional consequences of a cosmetic tongue split operation for speech and tongue motility. One male patient who had performed the operation on himself was interviewed and underwent a tongue motility assessment, as well as an ultrasound examination. Tongue motility was mildly reduced as a result of tissue scarring. Speech was rated to be fully intelligible and highly acceptable by 4 raters, although 2 raters noticed slight distortions of the sibilants /s/ and /z/. The 3-dimensional ultrasound demonstrated that the synergy of the 2 sides of the tongue was preserved. A notably deep posterior genioglossus furrow indicated compensation for the reduced length of the tongue blade. It is concluded that the tongue split procedure did not significantly affect the participant's speech intelligibility and tongue motility.},
    archivePrefix = {arXiv},
    arxivId = {arXiv:1011.1669v3},
    author = {Lundie, A. E.},
    doi = {10.1007/s13398-014-0173-7.2},
    eprint = {arXiv:1011.1669v3},
    isbn = {9780874216561},
    issn = {0717-6163},
    journal = {United States Department of Agriculture},
    keywords = {12,2007,3,Adolescence,Adolescencia,Adolescent,Adolescent Behavior,Adolescent Behavior: psychology,Adult,Agresiones al cuerpo,Attachment to the body,Attaque au corps,Autolesiones deliberadas,Automutilation d{\'{e}}lib{\'{e}}r{\'{e}}e,Body Piercing,Body Piercing: psychology,Body Piercing: statistics {\&} numerical data,Body image,CUERPO,Chile,Chile: epidemiology,Cornway,Corporate Finance,Cosmetic Techniques,Deliberate self-harm,Epidemiologic Methods,Female,Humans,Image corporelle,Imagen corporal,Industrial Organization,J.,JUVENTUD,Lumb,MODIFICACIONES CORPORALES,Male,Masood,Motivation,Movement,Public,R.,Risk-Taking,S.,S.K.,Self Mutilation,Self Mutilation: physiopathology,Self Mutilation: ultrasonography,Sex Distribution,Skan,Speech Articulation Tests,Speech Intelligibility,Tattooing,Tattooing: psychology,Tattooing: statistics {\&} numerical data,Tongue,Tongue: injuries,Tongue: physiopathology,Tongue: ultrasonography,advantages,aesthetics,and e-banking,and on cor-,anomaly detection,as none were found,authentication,autoinjury and health,body,business model,candidate,classification,collaboration,competition,complications did not,complications from inserting a,constituci{\'{o}}n del yo,control postural- estabilizaci{\'{o}}n- v{\'{i}}as,corporal modifications,corps,credit access,credit financing,credit score,credit scoring,critical success factors,cuerpo,culturas juveniles,cultures juv{\'{e}}niles,customer satisfaction,customer scoring,data mining,decision tree,department of economics at,e-,e- banking,e-banking,e-commerce,e-payment,e-trading,electronic communication and computation,emergency,endogenous tie,epidural,esth{\'{e}}tique,est{\'{e}}tica,feature sim-,finance includes e-payment,financial fervices technology,financial services innovation,find any reports of,fintech,fintech analysis,fintech start-ups,functions,genetic programming,global fintech comparison,high resolution images,if neuraxial anes-,in practice,indonesia,information technology,ing with neuraxial anesthesia,internet bank,internet primary bank,jarunee wonglimpiyarat,jeunesse,jibc december 2007,juvenile cultures,juventud,limitations,luation of non-urgent visits,m-commerce,mecanismos de anteroalimentaci{\'{o}}n y,modificacio -,multimodal biometric,needle through a,nes corporales,network security,networks,neural networks,no,patents analysis,perforaci{\'{o}}n corporal,piel,professor of marketing,professor of marketing at,pr{\'{a}}ctica autolesiva,psicoan{\'{a}}lisis,recommender system,research,retroalimentaci{\'{o}}n,risks management,segunda piel,sensitivas y motoras,smart cards,social network analysis,social networks,social status,spinal,strategic,strategy,support vector machine,sustainable reconstruction,sydney fintech,sydney start-ups,tattoo,tattooing,tattoos,tatuaje,the literature on tattoos,the university of pennsylvania,the wharton school of,to a busy urban,traditional banking services,unimodal biometric,university of pennsylvania,vol,was reviewed to see,youth},
    pages = {1--38},
    pmid = {15003161},
    title = {{The flight activities of the honeybee}},
    url = {https://archive.org/details/flightactivities1328lund},
    volume = {1328},
    year = {1925}
}

@article{ art:struye1994,
    abstract = {An important parameter in evaluating the activity of a honeybee colony is given by the number of bees leaving and entering the hive as a function of time. The microprocessor-controlled counter described here presents many advantages over previous counting devices. The counter fits the standard hive measurement (10 combs), and provides access to the hive via 32 bi- directional channels. The very small infrared detectors in each channel are only 0.1 mm apart, and are controlled by an asynchronous sequential algorithm, which improves the counter's precision. Results of measurements of the daily activity of honeybee colonies under different conditions (normal, in the presence of pesticides, or during swarming) are presented},
    author = {Struye, M H and Mortier, H J and Arnold, G and Miniggio, C and Borneck, R},
    doi = {10.1051/apido:19940405},
    issn = {0044-8435},
    journal = {Apidologie},
    number = {4},
    pages = {384--395},
    title = {{Microprocessor-controlled monitoring of honeybee flight activity at the hive entrance}},
    url = {https://hal.archives-ouvertes.fr/hal-00891170/document},
    volume = {25},
    year = {1994}
}

@article{ art:campbell2005,
    abstract = {A sensor has been developed to monitor objects passing through tunnels using a capacitance bridge. While the sensor concept is easily adaptable to a wide range of objects or organisms which pass through an enclosed area, our version of the sensor was designed specifically for monitoring bumblebee colonies. Other bee sensors have been developed based on optical methods of detection. The capacitance sensor provides all the information of the optical sensors and additional information on the bee blobSize and velocity. The sensor is expected to provide entomologists with more efficient methods of studying the foraging activities of bees.},
    author = {Campbell, Jennifer M and Dahn, Douglas C and Ryan, Daniel A J},
    doi = {10.1088/0957-0233/16/12/015},
    isbn = {0957-0233},
    issn = {0957-0233},
    journal = {Measurement Science and Technology},
    keywords = {bee counter,bombus,capacitance bridge,capacitance sensor,counting,foraging dynamics,insect activity monitor,tunnel},
    number = {12},
    pages = {2503--2510},
    title = {{Capacitance-based sensor for monitoring bees passing through a tunnel}},
    url = {http://stacks.iop.org/0957-0233/16/i=12/a=015},
    volume = {16},
    year = {2005}
}

@misc{ beebarcode,
    author = "Express Label Company",
    title = "Barcode Labels Many Uses",
    year = "2009",
    url = {http://www.uprintlabels.com/barcode-labels-uses.html},
    note = "[Online; Accedido 02-Noviembre-2016]"
}

@article{ art:decourtye_honeybee_2011,
    abstract = {Losses of foraging bees are sometimes attributed to altered flight pattern between a meliferous plant treated with an insecticide and the hive. Only a limited number of studies has investigated the impact of pesticides on homing flight due to the difficulty of measuring the flight time between the food source and the hive. Monitoring the flights of the foraging bees needs their individual identification. The number of bees monitored simultaneously and the time span during which observations can be made limit most of the monitoring techniques. However, techniques of automatic tracking and identification of individuals have the potential to revolutionize the study of the ecotoxicological effects of xenobiotics on the bee behaviors. Radio Frequency Identification (RFID) offer numerous advantages such as an unlimited number of codes, a large number of simultaneous recording, and a quick reading, especially through materials (e.g., wood). The aim of this study was to show how the RFID device can be used to study the effects of pesticides on both the behavioral traits and the lifespan of bees. In this context, we have developed a method under tunnel to automatically record the displacements of foragers individualized with RFID tags and to detect the alteration of the flight pattern between an artificial feeder and the hive. Fipronil was selected as test substance due to the lack of information on the effects of this insecticide on the foraging behavior of free-flying bees. We showed that oral treatment of 0.3 ng of fipronil per bee (LD50/20) reduced the number of foraging trips. The strengths of our approach were briefly discussed.},
    author = {Decourtye, Axel and Devillers, James and Aupinel, Pierrick and Brun, Fran{\c{c}}ois and Bagnis, Camille and Fourrier, Julie and Gauthier, Monique},
    doi = {10.1007/s10646-011-0594-4},
    isbn = {1573-3017 (Electronic)$\backslash$n0963-9292 (Linking)},
    issn = {09639292},
    journal = {Ecotoxicology},
    keywords = {Automatic monitoring,Foraging,Honeybee,Life-history traits,Pesticides,RFID tags},
    number = {2},
    pages = {429--437},
    pmid = {21267650},
    title = {{Honeybee tracking with microchips: A new methodology to measure the effects of pesticides}},
    url = {https://www.ncbi.nlm.nih.gov/pubmed/21267650},
    volume = {20},
    year = {2011}
}

@inproceedings{ art:chiron2013a,
    abstract = {This paper summarizes an approach based on stereo vision to recover honeybee trajectories in 3D at the beehive entrance. The 3D advantage offered by stereo vision is crucial to overcome the rough constraints of the application (number of bees, target dynamics and light). Biologists have highlighted the close scale influence of the environment on bees dynamics. We propose to transpose this idea to enhance our tracking process based on Global Nearest Neighbors. Our method normalizes track/observation association costs that are originally not uniformly distributed over the scene. Therefore, the structure of the scene is needed in order to compute relative distances with the targets. The beehive and especially the flight board is the referent environment for bees, so we propose a method to reconstruct the flight board surface from the noisy and incomplete disparity maps provided by the stereo camera},
    author = {Chiron, Guillaume and Gomez-Kr{\"{a}}mer, Petra and M{\'{e}}nard, Michel and Requier, Fabrice},
    booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
    doi = {10.1007/978-3-642-41181-6_71},
    isbn = {9783642411809},
    issn = {03029743},
    keywords = {3D tracking,beehive monitoring,honeybees,honeybees 3D tracking,stereo vision,surface reconstruction},
    mendeley-tags = {3D tracking,beehive monitoring,honeybees,stereo vision,surface reconstruction},
    number = {PART 1},
    pages = {702--711},
    publisher = {Springer Berlin Heidelberg},
    title = {{3D tracking of honeybees enhanced by environmental context}},
    url = {http://link.springer.com/10.1007/978-3-642-41181-6\_71},
    volume = {8156 LNCS},
    year = {2013}
}

@article{ art:chiron2013,
    author = {Chiron, Guillaume and Gomez-Kr{\"{a}}mer, Petra and M{\'{e}}nard, Michel},
    doi = {10.1186/1687-5281-2013-59},
    issn = {1687-5281},
    journal = {EURASIP Journal on Image and Video Processing},
    keywords = {3d multi-target tracking,beehive monitoring,honeybee,rgb-d segmentation,stereo vision},
    number = {1},
    pages = {59},
    title = {{Detecting and tracking honeybees in 3D at the beehive entrance using stereo vision}},
    url = {http://jivp.eurasipjournals.com/content/2013/1/59},
    volume = {2013},
    year = {2013}
}

@inproceedings{ art:tashakkori2015,
    abstract = {Honey bees are responsible for more than half of the pollination across the world, hence they have an important role in agriculture. In recent years, the number of honey bees have declined due to the Colony Collapse Disorder (CCD), which may be due to possible causes that include climate change and pollution. Since honey bees start from their hives to go for pollination, their activities around the hive are a good indicator of their health. The bee hive's health status and the activities of honey bees can be related to the environment in which they live, thus finding a quantitative measure of the bee activities is very important and can benefit the beekeepers. This paper will present a data acquisition and monitoring system that utilizes image processing techniques for extracting data from the videos of the bee hive's entrance taken at the front or the top of the hive's entrance. The system developed as part of this research utilizes two different approaches based on the Illumination-invariant Change Detection Algorithm and Signal-to-Noise Ratio to estimate the number of bees at the entrance of the hives.},
    address = {Fort Lauderdale, FL},
    author = {Tashakkori, Rahman and Ghadiri, Ahmad},
    booktitle = {SoutheastCon 2015},
    doi = {10.1109/SECON.2015.7133029},
    isbn = {978-1-4673-7300-5},
    issn = {07347502},
    month = {apr},
    pages = {1--7},
    publisher = {IEEE},
    title = {{Image processing for honey bee hive health monitoring}},
    url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7133029},
    year = {2015}
}

@misc{ wiki:bs,
    author = "Wikipedia",
    title = "Background subtraction --- {Wikipedia}{,} {The Free Encyclopedia}",
    year = "2016",
    url = {https://en.wikipedia.org/w/index.php?title=Background\_subtraction&oldid=741230478},
    note = "[Online; Accedido 23-Septiembre-2016]"
}
 
@misc{ opencv:bs_tutorial,
    author = "OpenCV",
    title = "{OpenCV} Background Subtraction tutorial",
    year = "2016",
    url = {http://docs.opencv.org/master/db/d5c/tutorial\_py\_bg\_subtraction.html},
    note = "[Online; Accedido 26-Septiembre-2016]"
}

@book{ book:opencv_java,
	title = {{OpenCV} 3.0 {Computer} {Vision} with {Java}},
	isbn = {9781783283972},    
	abstract = {OpenCV 3.0 Computer Vision with Java is a practical tutorial guide that explains fundamental tasks from computer vision while focusing on Java development. This book will teach you how to set up OpenCV for Java and handle matrices using the basic operations of image processing such as filtering and image transforms. It will also help you learn how to use Haar cascades for tracking faces and to detect foreground and background regions with the help of a Kinect device. It will even give you insights into server-side OpenCV. Each chapter is presented with several projects that are ready to use. The functionality of these projects is found in many classes that allow developers to understand computer vision principles and rapidly extend or customize the projects for their needs.},
	language = {Inglés},
	publisher = {Packt Publishing},
	author = {Baggio, Daniel Lélis},
	month = jul,
	year = {2015}
}

@book{ book:learning_cv,
	title = {Learning {Image} {Processing} with {OpenCV}},
	isbn = {978-1-78328-765-9},
	abstract = {Exploit the amazing features of OpenCV to create powerful image processing applications through easy-to-follow examples About This BookLearn how to build full-fledged image processing applications using free tools and librariesTake advantage of cutting-edge image processing functionalities included in OpenCV v3Understand and optimize various features of OpenCV with the help of easy-to-grasp examplesWho This Book Is ForIf you are a competent C++ programmer and want to learn the tricks of image processing with OpenCV, then this book is for you. A basic understanding of image processing is required.What You Will Learn Create OpenCV programs with rich user interfaces  Grasp basic concepts and tasks in image processing such as image types, pixel access techniques, and arithmetic operations with images and histograms  Explore useful image processing techniques such as filtering, smoothing, sharpening, denoising, morphology, and geometrical transformations  Get to know handy algorithms such as inpainting and LUTs  Leverage the color manipulation features of OpenCV to optimize image processing  Discover how to process a video and the main techniques involved such as stabilization, stitching, and even superresolution  Understand the new computational photography module that covers high-dynamic range imaging, seamless cloning, decolorization, and non-photorealistic rendering  In DetailOpenCV, arguably the most widely used computer vision library, includes hundreds of ready-to-use imaging and vision functions and is used in both academia and enterprises.This book provides an example-based tour of OpenCV's main image processing algorithms. Starting with an exploration of library installation, wherein the library structure and basics of image and video reading/writing are covered, you will dive into image filtering and the color manipulation features of OpenCV with LUTs. You'll then be introduced to techniques such as inpainting and denoising to enhance images as well as the process of HDR imaging. Finally, you'll master GPU-based accelerations. By the end of this book, you will be able to create smart and powerful image processing applications with ease! All the topics are described with short, easy-to-follow examples.},
	language = {English},
	publisher = {Packt Publishing - ebooks Account},
	author = {Garcia, Gloria Bueno and Suarez, Oscar Deniz and Aranda, Jose Luis Espinosa and Tercero, Jesus Salido and Gracia, Ismael Serrano},
	month = mar,
	year = {2015}
}

@misc{ course:android_beginners,
	title = {Android {Development} for {Beginners}: {How} to {Make} {Apps} {\textbar} {Udacity}},
	shorttitle = {Android {Development} for {Beginners}},
	url = {https://www.udacity.com/course/android-development-for-beginners--ud837},
	abstract = {Learn the basics of Android and Java programming. This class is designed for students who are new to programming and want to build Android apps.},
	language = {English},
	author = {Kuan, Katherine and Chawla, Kunal and Fujiwara, Lyla},
	year = {2016},
    note = "[Online; Accedido 5-Octubre-2016]"
}

@misc{ course:developing_android,
	title = {Developing {Android} {Apps} {\textbar} {Udacity}},
	url = {https://www.udacity.com/course/new-android-fundamentals--ud851},
	abstract = {Learn how to develop Android applications from scratch using development best practices through a hands on course led by Google instructors.},
	language = {English},
	author = {Galpin, Dan and Fujiwara, Lyla and Meier, Reto and Samak, Asser and Williams, James and Camacho, Cezanne and Lustig, Michael},
	year = {2016},
    note = "[Online; Accedido 5-Octubre-2016]"
}

@misc{ course:testing,
	title = {Android {Testing} {Codelab}},
	url = {https://codelabs.developers.google.com/codelabs/android-testing/},
	language = {English},
	author = {Google Inc.},
	year = {2016},
    note = "[Online; Accedido 5-Octubre-2016]"
}

@misc{ programarfacil:detmov,
    author = "Luis del Valle Hernández",
    title = "Detección de movimiento con {OpenCV} y {Python}",
    year = "2016",
    url = {http://programarfacil.com/blog/vision-artificial/deteccion-de-movimiento-con-opencv-python/},
    note = "[Online; Accedido 5-Octubre-2016]"
}

@misc{ coursera:gmm,
    author = "University of Pennsylvania",
    title = "Robotics: Estimation and Learning: {Gaussian Mixture Model} ({GMM})",
    year = "2016",
    url = {https://www.coursera.org/learn/robotics-learning/lecture/XG0WD/1-4-1-gaussian-mixture-model-gmm/},
    note = "[Online; Accedido 5-Octubre-2016]"
}

@article{ art:yao_improved_2001,
	title = {An {Improved} {Mixture}-of-{Gaussians} {Background} {Model} with {Frame} {Difference} and {Blob} {Tracking} in {Video} {Stream}},
	volume = {2014},
	issn = {2356-6140},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4000660/},
	doi = {10.1155/2014/424050},
	abstract = {Modeling background and segmenting moving objects are significant techniques for computer vision applications. Mixture-of-Gaussians (MoG) background model is commonly used in foreground extraction in video steam. However considering the case that the objects enter the scenery and stay for a while, the foreground extraction would fail as the objects stay still and gradually merge into the background. In this paper, we adopt a blob tracking method to cope with this situation. To construct the MoG model more quickly, we add frame difference method to the foreground extracted from MoG for very crowded situations. What is more, a new shadow removal method based on RGB color space is proposed.},
	urldate = {2016-10-12},
	journal = {The Scientific World Journal},
	author = {Yao, Li and Ling, Miaogen},
	month = apr,
	year = {2014},
	pmid = {25161393},
	pmcid = {PMC4000660},
	file = {PubMed Central Full Text PDF:C\:\\Users\\ddmll\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\g479gg1a.default\\zotero\\storage\\PU95EXAT\\Yao y Ling - 2014 - An Improved Mixture-of-Gaussians Background Model .pdf:application/pdf}
}

@inproceedings{ art:zivkovic_improved_2004,
	address = {Washington, DC, USA},
	series = {{ICPR} '04},
	title = {Improved {Adaptive} {Gaussian} {Mixture} {Model} for {Background} {Subtraction}},
	isbn = {978-0-7695-2128-2},
	url = {https://pdfs.semanticscholar.org/56b1/eee82a51ce17d72a91b5876a3281418679cc.pdf},
	doi = {10.1109/ICPR.2004.479},
	abstract = {Background subtraction is a common computer vision task. We analyze the usual pixel-level approach. We develop an efficient adaptive algorithm using Gaussian mixture probability density. Recursive equations are used to constantly update the parameters and but also to simultaneously select the appropriate number of components for each pixel.},
	urldate = {2016-10-12},
	booktitle = {Proceedings of the {Pattern} {Recognition}, 17th {International} {Conference} on ({ICPR}'04) {Volume} 2 - {Volume} 02},
	publisher = {IEEE Computer Society},
	author = {Zivkovic, Zoran},
	year = {2004},
	pages = {28--31}
}

@article{ art:zivkovic_efficient_2006,
	title = {Efficient {Adaptive} {Density} {Estimation} {Per} {Image} {Pixel} for the {Task} of {Background} {Subtraction}},
	volume = {27},
	issn = {0167-8655},
	url = {http://www.zoranz.net/Publications/zivkovicPRL2006.pdf},
	doi = {10.1016/j.patrec.2005.11.005},
	abstract = {We analyze the computer vision task of pixel-level background subtraction. We present recursive equations that are used to constantly update the parameters of a Gaussian mixture model and to simultaneously select the appropriate number of components for each pixel. We also present a simple non-parametric adaptive density estimation method. The two methods are compared with each other and with some previously proposed algorithms.},
	number = {7},
	urldate = {2016-10-12},
	journal = {Pattern Recogn. Lett.},
	author = {Zivkovic, Zoran and van der Heijden, Ferdinand},
	month = may,
	year = {2006},
	keywords = {Background subtraction, Gaussian mixture model, Non-parametric density estimation, On-line density estimation},
	pages = {773--780}
}

@misc{ github:background_segm,
    author = "OpenCV",
    title = "Interfaz {BackgroundSubtractorMOG2} (background\_segm.hpp)",
    year = "2016",
    url = {https://github.com/opencv/opencv/blob/master/modules/video/include/opencv2/video/background\_segm.hpp},
    note = "[Online; Accedido 12-Octubre-2016]"
}

@misc{ github:bgfg_gaussmix2,
    author = "OpenCV",
    title = "Implementación {BackgroundSubtractorMOG2} (bgfg\_gaussmix2.cpp)",
    year = "2016",
    url = {https://github.com/opencv/opencv/blob/master/modules/video/src/bgfg\_gaussmix2.cpp},
    note = "[Online; Accedido 12-Octubre-2016]"
}

@misc{ opencv:mog2,
    author = "OpenCV",
    title = "{cv::BackgroundSubtractorMOG2} Class Reference",
    year = "2016",
    url = {http://docs.opencv.org/3.1.0/d7/d7b/classcv\_1\_1BackgroundSubtractorMOG2.html},
    note = "[Online; Accedido 12-Octubre-2016]"
}

@misc{ wiki:grayscale,
    author = "Wikipedia",
    title = "Grayscale --- {Wikipedia}{,} {The Free Encyclopedia}",
    year = "2016",
    url = {https://en.wikipedia.org/w/index.php?title=Grayscale&oldid=742147487},
    note = "[Online; Accedido 18-Octubre-2016]"
}

@misc{ opencv:color_cvt,
    author = "OpenCV",
    title = "Color conversions",
    year = "2016",
    url = {http://docs.opencv.org/3.1.0/de/d25/imgproc\_color\_conversions.html},
    note = "[Online; Accedido 18-Octubre-2016]"
}

@misc{ wiki:gaussian,
    author = "Wikipedia",
    title = "Gaussian blur --- {Wikipedia}{,} {The Free Encyclopedia}",
    year = "2016",
    url = {https://en.wikipedia.org/w/index.php?title=Gaussian\_blur&oldid=739396767},
    note = "[Online; Accedido 18-Octubre-2016]"
}

@book{ book:mastering_opencv,
    title = {Mastering {OpenCV} {Android} {Application} {Programming}},
	isbn = {978-1783988204},    
    abstract = {Master the art of implementing computer vision algorithms on Android platforms to build robust and efficient applicationsAbout This BookUnderstand and utilise the features of OpenCV, Android SDK, and OpenGLDetect and track specific objects in a video using Optical Flow and Lucas Kanade TrackerAn advanced guide full of real-world examples, helping you to build smart OpenCV Android applicationsWho This Book Is ForIf you are a Java and Android developer looking to enhance your skills by learning the latest features of OpenCV Android application programming, then this book is for you.What You Will LearnUnderstand image processing using OpenCVDetect specific objects in an image or video using various state-of-the-art feature-matching algorithms such as SIFT, SURF, and ORBPerform image transformations such as changing color, space, resizing, applying filters like Gaussian blur, and likesUse mobile phone cameras to interact with the real worldExplore face detection, object detection, and image stitching in OpenCV Android programmingBuild smarter applications by using machine learning algorithmsLearn to debug applications and create optimal custom algorithms by understanding how data is stored internallyIn DetailOpenCV is a famous computer vision library, used to analyze and transform copious amounts of image data, even in real time and on a mobile device.This book focuses on leveraging mobile platforms to build interactive and useful applications. The book starts off with an introduction to OpenCV and Android and how they interact with each other using OpenCV's Java API. You'll also discover basic image processing techniques such as erosion and dilation of images, before walking through how to build more complex applications, such as object detection, image stitching, and face detection. As you progress, you will be introduced to OpenCV's machine learning framework, enabling you to make your applications smarter.The book ends with a short chapter covering useful Android tips and tricks and some common errors and solutions that people might face while building an application. By the end of the book, readers will have gained more expertise in building their own OpenCV projects for the Android platform and integrating OpenCV application programming into existing projects.},
    language = {Inglés},
    publisher = {Packt Publishing},
    author = {Kapur, Salil},
    month = jul,
    year = {2015}
}

@book{ book:android_opencv,
	title = {Android {Application} {Programming} with {OpenCV} 3},
	isbn = {978-1-78528-538-7},
	abstract = {If you are a Java developer who is new to computer vision and would like to learn through application development, then this book is for you. You are expected to have a mobile device running Android 2.2 (Froyo) or greater, including a camera. Experience in Java is a must.},
	language = {Inglés},
	publisher = {Packt Publishing},
	author = {Howse, Joseph},
	month = jun,
	year = {2015}
}

@misc{ opencv:find_contours,
    author = "OpenCV",
    title = "Structural Analysis and Shape Descriptors",
    year = "2016",
    url = {docs.opencv.org/3.0-beta/modules/imgproc/doc/structural\_analysis\_and\_shape\_descriptors.html},
    note = "[Online; Accedido 19-Octubre-2016]"
}

@misc{ opencv:contours,
    author = "OpenCV",
    title = "Contours in {OpenCV}",
    year = "2016",
    url = {http://docs.opencv.org/3.0-beta/doc/py\_tutorials/py\_imgproc/py\_contours/py\_table\_of\_contents\_contours/py\_table\_of\_contents\_contours.html},
    note = "[Online; Accedido 19-Octubre-2016]"
}

@misc{ gobees:web,
    author = "David Miguel Lozano",
    title = "Sitio web de {GoBees}",
    year = "2016",
    url = {http://gobees.io/},
    note = "[Online; Accedido 25-Enero-2017]"
}

@misc{ gobees:repo,
    author = "David Miguel Lozano",
    title = "Repositorio de {GoBees} en {GitHub}",
    year = "2016",
    url = {https://github.com/davidmigloz/go-bees/},
    note = "[Online; Accedido 25-Enero-2017]"
}

@misc{ gobees:play,
    author = "David Miguel Lozano",
    title = "GoBees en {Google} {Play}",
    year = "2016",
    url = {https://play.google.com/store/apps/details?id=com.davidmiguel.gobees},
    note = "[Online; Accedido 25-Enero-2017]"
}

@misc{ gobees:prototipes,
    author = "David Miguel Lozano",
    title = "Repositorio de las herramientas desarrolladas para {GoBees} en {GitHub}",
    year = "2016",
    url = {https://github.com/davidmigloz/go-bees-prototypes},
    note = "[Online; Accedido 25-Enero-2017]"
}

@misc{ pattern:mvp,
    author = "Martin Fowler",
	title = {GUI Architectures - {MVC} and {MVP}},
    year = "2006",
	url = {https://martinfowler.com/eaaDev/uiArchs.html},
	note = "[Online; Accedido 22-Enero-2017]"
}

@misc{ pattern:repository,
    author = "Martin Fowler, Edward Hieatt, Rob Mee",
	title = {Repository Pattern},
	url = {https://martinfowler.com/eaaCatalog/repository.html},
	note = "[Online; Accedido 22-Enero-2017]"
}

@misc{ wiki:scrum,
    author = "Wikipedia",
	title = {Scrum (software development) --- {Wikipedia}{,} {The Free Encyclopedia}},
    year = "2017",
	url = {https://en.wikipedia.org/w/index.php?title=Scrum\_(software\_development)&oldid=761729658},
	note = "[Online; Accedido 26-Enero-2017]"
}

@misc{ wiki:tdd,
    author = "Wikipedia",
	title = {Test-driven development --- {Wikipedia}{,} {The Free Encyclopedia}},
    year = "2017",
	url = {https://en.wikipedia.org/w/index.php?title=Test-driven\_development&oldid=758403369},
    note = "[Online; Accedido 26-Enero-2017]"
}

@misc{ git:gitflow,
    author = "Vincent Driessen",
	title = {Gitflow - A successful {Git} branching model},
    year = "2010",
	url = {http://nvie.com/posts/a-successful-git-branching-model/},
    note = "[Online; Accedido 26-Enero-2017]"
}

@misc{ android:versions,
    author = "Google",
	title = {Platform Versions - {Google Developers}},
    year = "2017",
	url = {https://developer.android.com/about/dashboards/},
    note = "[Online; Accedido 28-Enero-2017]"
}

@misc{ wiki:pomodoro,
    author = "Wikipedia",
	title = {Pomodoro Technique --- {Wikipedia}{,} {The Free Encyclopedia}},
    year = "2017",
	url = {https://en.wikipedia.org/w/index.php?title=Pomodoro\_Technique&oldid=760673890},
    note = "[Online; Accedido 26-Enero-2017]"
}
